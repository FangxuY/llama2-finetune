{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee32f377-3d63-43e1-83dd-064364d1d829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting IProgress\n",
      "  Downloading IProgress-0.4-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: six in /home/zhiyuan/anaconda3/envs/finetune2/lib/python3.9/site-packages (from IProgress) (1.16.0)\n",
      "Installing collected packages: IProgress\n",
      "Successfully installed IProgress-0.4\n"
     ]
    }
   ],
   "source": [
    "!pip install IProgress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9e0fd16-27c4-47bb-b702-6785fee7d34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import datasets\n",
    "from transformers import LlamaTokenizer\n",
    "tokenizer = LlamaTokenizer.from_pretrained(\"/home/zhiyuan/llama2-recipe/Llama-2-13b-chat-hf\")\n",
    "split = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b035b536-0176-45a1-8483-1874cfa73737",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-752d0013d179bdc9\n",
      "Reusing dataset json (/home/zhiyuan/.cache/huggingface/datasets/json/default-752d0013d179bdc9/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.009815692901611328,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a7aadb7c323479e8a59d194805495cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = datasets.load_dataset(\"json\", data_files='CommSense.json', field=split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b3e5fdd-c45d-45b8-90fb-80aa59f83e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['question', 'answer'],\n",
      "        num_rows: 8\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "def apply_prompt_template(sample):\n",
    "    return {\n",
    "        \"question\": sample[\"question\"],\n",
    "        \"answer\": sample[\"answer\"],\n",
    "    }\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd0a41d0-12db-484f-b966-34675d712f82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.010803937911987305,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 8,
       "unit": "ex",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88aa943a5c5f4bb1aa167ff6d5402eab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.map(apply_prompt_template, remove_columns=list(dataset['train'].features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c369fe2-87c3-42eb-9225-73f5ae5b79c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004243135452270508,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 8,
       "unit": "ex",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb7580bb314c466aa1ff0b53f302e1bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def tokenize_add_label(sample):\n",
    "    question = tokenizer.encode(tokenizer.bos_token + sample[\"question\"], add_special_tokens=False)\n",
    "    answer = tokenizer.encode(sample[\"answer\"] +  tokenizer.eos_token, add_special_tokens=False)\n",
    "\n",
    "    sample = {\n",
    "        \"input_ids\": question + answer,\n",
    "        \"attention_mask\" : [1] * (len(question) + len(answer)),\n",
    "        \"labels\": [-100] * len(question) + answer,\n",
    "    }\n",
    "\n",
    "    return sample\n",
    "    \n",
    "dataset = dataset.map(tokenize_add_label, remove_columns=list(dataset['train'].features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a9a29870-8c3c-4b64-bf66-d424f4d45571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 8\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset_val = dataset\n",
    "print(dataset_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "136263b2-4320-487d-bbeb-5e7cc1f574e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class ConcatDataset(Dataset):\n",
    "    def __init__(self, dataset, chunk_size=4096):\n",
    "        self.dataset = dataset\n",
    "        self.chunk_size = chunk_size\n",
    "\n",
    "        self.samples = []\n",
    "\n",
    "        buffer = {\n",
    "            \"input_ids\": [],\n",
    "            \"attention_mask\": [],\n",
    "            \"labels\": [],\n",
    "            }\n",
    "\n",
    "        for sample in tqdm(self.dataset, desc=\"Preprocessing dataset\", dynamic_ncols=True):\n",
    "            buffer = {k: v + sample[k] for k,v in buffer.items()}\n",
    "\n",
    "            while len(next(iter(buffer.values()))) > self.chunk_size:\n",
    "                self.samples.append({k: v[:self.chunk_size] for k,v in buffer.items()})\n",
    "                buffer = {k: v[self.chunk_size:] for k,v in buffer.items()}\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81f8ef4-d6cb-4da6-b158-7e0d2880d939",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
